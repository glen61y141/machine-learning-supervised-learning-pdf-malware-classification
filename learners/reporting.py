import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split, GridSearchCV, learning_curve

def results(
        pipe, 
        params,
        data,
        clf_name,
        title_params=[],
        cv=5, 
        jobs=1, 
        verbose=10
    ):
    X = data.drop('class', 1).copy().values
    y = data['class'].copy().values
    train_x, test_x, train_y, test_y = train_test_split(X, y, test_size=0.3, shuffle=True, random_state=60)
    clf = GridSearchCV(pipe, params, cv=cv, n_jobs=jobs, verbose=verbose)
    clf.fit(train_x, train_y)
    score = clf.score(test_x, test_y)
    
    title_best_params = '| '
    best_params = clf.best_estimator_.named_steps[clf_name].get_params()
    for name in title_params:
        title_best_params += '{}: {} | '.format(name, best_params[name])

    title = '{} Learning Curve | Accuracy: {}%\n{}'.format(clf_name, '{0:.2f}'.format(score *100), title_best_params)
    plot_learning_curve(clf.best_estimator_, title, clf_name=clf_name, data=(X,y), cv=2)

def plot_learning_curve(
        estimator,
        title,
        data,
        clf_name,
        ylim=None,
        cv=None,
        n_jobs=None,
        train_sizes=np.linspace(.1, 1.0, 5)
    ):
    X, y = data
    plt.figure()
    plt.title(title)
    if ylim is not None:
        plt.ylim(*ylim)
    plt.xlabel('Training examples')
    plt.ylabel('Error')
    train_sizes, train_scores, test_scores = learning_curve(
        estimator, 
        X,
        y,
        cv=cv,
        n_jobs=n_jobs,
        train_sizes=train_sizes,
        shuffle=True
    )
    
    train_errors = 1 - train_scores
    test_errors = 1 - test_scores
    train_errors_mean = np.mean(train_errors, axis=1)
    train_errors_std = np.std(train_errors, axis=1)
    test_errors_mean = np.mean(test_errors, axis=1)
    test_errors_std = np.std(test_errors, axis=1)
    
    plt.grid()
    plt.fill_between(train_sizes, train_errors_mean - train_errors_std,
                     train_errors_mean + train_errors_std, alpha=0.1,
                     color='r')
    plt.fill_between(train_sizes, test_errors_mean - test_errors_std,
                     test_errors_mean + test_errors_std, alpha=0.1, color='g')
    plt.plot(train_sizes, train_errors_mean, 'o-', color='r',
             label='Training Error')
    plt.plot(train_sizes, test_errors_mean, 'o-', color='g',
             label='Cross-validation Error')
    plt.legend(loc='best')
    plt.savefig('images/{}-learning-curve.png'.format(clf_name))
    return plt
